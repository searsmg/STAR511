---
title: "STAR511: HW 8"
author: "Megan Sears"
output: word_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
#Retain (and do not edit) this code chunk!!!
library(knitr)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)

library(tidyverse)
library(here)
library(ggplot2)

```

# Q1


```{r}
#Q1
prestige <- read.csv('./HW8/Prestige.csv', row.names=1)

pairs(prestige)

```


# Q2

```{r}
#Q2
cor(prestige)

```

# Q3

```{r}
#Q3
cor.test(x=prestige$income, y=prestige$prestige)

```

# Q4

```{r}
#Q4
summary(lm(prestige$prestige ~ prestige$income))

```

# Q5 

Based on the p-value (less than alpha) from Pearson's correlation and the correlation coefficient (0.71), there is a linear association between the two variables. Further, since there is a positive correlation (0.71), as income rises so does prestige. The null hypothesis, that there is no linear association or that the slope is 0, should be rejected based on the p-value from the correlation test and linear model (slope p-value). 

# Q6

The slope from the linear model is 0.0029 with an associate p-value less than 0.05. Therefore, for every dollar increase in income, prestige increases by an estimate value of 0.0029.


# Q7

```{r}
#Q7
model <- lm(prestige$prestige ~ prestige$income)

par(mfrow=c(1,2))

plot(model, which = c(1:2))

```

# Q8

```{r}
#Q8
model2 <- lm(prestige ~ income + education, data = prestige)
summary(model2)

```

# Q9

The slope from the linear model is 0.0014 with an associate p-value less than 0.05. Therefore, for every dollar increase in income, prestige increases by an estimate value of 0.0014. This is less than seen in question 6.

# Q10

```{r}
#Q10 
par(mfrow=c(1,2))

plot(model2, which = c(1:2))

```

# Q11 

The R-squared value is 0.798. This is a measure of how well the model is fitting the actual data. Approximately 80% of the variance found in prestige can be explained by income and education. 

# Q12

```{r}
#Q12
steel <- read_csv('./HW8/Steel.csv')

ggplot(steel, aes(x=Thick, y=Strength)) +
  geom_point() + 
  labs(x='Coating Thickness')

```

# Q13

```{r}
#Q13
steelmod <- lm(steel$Strength ~ steel$Thick)

par(mfrow=c(1,2))

plot(steelmod, which = c(1:2))

```

# Q14

No, the regression assumptions have not been met. The lower and higher values have lower range of residuals than the rest causing an almost upside u-shape in the data. Additionally, based on the Q-Q plot, the data are left skewed, or lower values are not near the line. 

# Q15

```{r}
#Q15
steelmod_quad <- lm(Strength ~ Thick + I(Thick^2), data = steel)

summary(steelmod_quad)

```

# Q16

```{r}
#Q16
par(mfrow=c(1,2))

plot(steelmod_quad, which = c(1:2))

```

Based on the Q-Q plot from Q15, the data appear to be normal especially when comparing the skew seen in this plot from Q13. The residuals plot still has larger range for tail ends of the data with values in between have a smaller range of residuals. 

# Q17

```{r}
qplot(x = Thick, y = Strength, data = steel) +
  geom_smooth(method = 'lm', formula = y ~ poly(x, 2), se = FALSE)

```




# Appendix
```{r show-code, ref.label = all_labels(), echo = TRUE, eval = FALSE}
```